# Sign-Language-Detection-App
This project is focused on creating a real-time sign language detection app that can recognize and interpret specific sign gestures from live video. The app will utilize Mediapipe, a framework for building real-time machine learning pipelines, to detect key points of the body, face, and hands. These key points are processed by a Long Short-Term Memory (LSTM) neural network, a type of recurrent neural network (RNN) well-suited for processing sequential data, to predict and classify sign language gestures. 

‚≠ê Features
- Real-time Gesture Recognition ‚Äì Detects and classifies sign language gestures from live video.
- Custom Dataset ‚Äì Trained on a manually collected dataset of sign gestures.
- Deep Learning-Based ‚Äì Uses an LSTM model for accurate sign detection.
- Mediapipe Integration ‚Äì Utilizes advanced hand and body tracking for precise keypoint extraction.
- User-Friendly Interface ‚Äì Runs on Jupyter Notebook for easy execution and visualization.

üõ†Ô∏è Tech Stack
    - Programming Language:	Python 
    - Computer Vision:	OpenCV 
    - Machine Learning Framework:	TensorFlow/Keras 
    - Deep Learning Model:	LSTM (Long Short-Term Memory) 
    - Pose & Hand Tracking:	Mediapipe 
    - Data Processing:	NumPy & Pandas 
    - Visualization:	Matplotlib 

üîß Installation & Setup

1Ô∏è‚É£ Install Dependencies

Ensure you have Python installed. Then, run the following command:
pip install opencv-python numpy mediapipe tensorflow scikit-learn matplotlib

2Ô∏è‚É£ Clone the Repository

git clone https://github.com/ShivankBhasin/https://github.com/ShivankBhasin/Sign-Language-Detection-App.git

cd Sign-Language-Detection-App

3Ô∏è‚É£ Run the Jupyter Notebook
- Open the notebook and execute all cells to train the model.
- Once trained, run the sign detection script to start real-time recognition.

üéØ How It Works
 - Captures real-time video feed using OpenCV.
 - Uses Mediapipe to extract keypoints from hands, face, and body.
 - Feeds the extracted features into an LSTM model trained on sign gestures.
 - Classifies the sign and displays the recognized word on the screen.
