# Sign-Language-Detection-App
This project is focused on creating a real-time sign language detection app that can recognize 
and interpret specific sign gestures from live video. The app will utilize Mediapipe, a 
framework for building real-time machine learning pipelines, to detect key points of the body, 
face, and hands. These key points are processed by a Long Short-Term Memory (LSTM) 
neural network, a type of recurrent neural network (RNN) well-suited for processing sequential 
data, to predict and classify sign language gestures. 
